## **Протестированные гипотезы**

---

### **Векторизация**
1. **TF-IDF**
> **Идея:** Учитывать не только количество вхождений, но и «уникальность» слова, то есть частоту его встречаемости во всей выборке (Inverse Document Frequency).

 > **Результат:** Показывает высокие показатели по метрикам (F1=~90%). Не полностью решает проблему дисбаланса классов.
 
 > Можно использовать class_weight со значением "balanced_subsample", что немного уменьшит точность на многочисленных и увеличит на малочисленных классах. Если важно распознавать малочисленные классы.

 > Также были проверены значения ngram_range: (1,2) и (1,3). Но результаты стали хуже, поэтому лучше использовать значение по умолчанию.


2. **OHE**
> **Идея:** Преобразовать значения каждого столбца в вектора признаков, где каждый признак соответствует наличию конкретного слова в документе.

 > **Результат:** По метрикам показывает результаты гораздо хуже, чем TF-IDF. Малочисленные классы плохо определяются.


3. **Комбинированный подход: TF-IDF + OHE**
> **Идея:** Поделить столбцы на 2 категории, текстовые и категориальные по количеству уникальных значений. Для категориальных использовать OHE, а для текстовых TF-IDF. 

 > **Результат:** По итогу ручной подбор категорий показал лучшие результаты. Удалось получить лучший результат (F1=~93%), при тестировании разных комбинаций столбцов. Такой результат сравним с обучением CatBoost, но при этом обучение такой модели гораздо быстрее.

4. **HashingVectorizer**
> **Идея:** Преобразовать текст в числовые векторы с помощью хэширования, без хранения словаря, с фиксированным размером выходного вектора. 

 > **Результат:** Немного увеличивает точность на больших классах и уменьшает на малочисленных по сравнением с TF-IDF.

5. **Семантические векторные представления (Embedding)**
> Был протестирован BERT. По результат сравним с HashingVectorizer. Не даёт прироста к точности.


---
### **Модели:**
1. **RandomForest**
> Базовая модель для тестов.
2. **LogisticRegression**
> Показывает результаты хуже, чем RandomForest.
3. **CatBoost**
> Мощная модель, с которой можно достичь лучших результатов при длительном обучении. За 10000 итераций обучения удалось достичь хороших результатов (F1=~92%), и процент точности продолжает повышаться. Но если данные будут часто менятся, то лучше использовать более простую и легковесную модель, так как обучение занимает много времени, а также необходим GPU для ускорения обучения.

---

### **База данных:**
* Для улучшения точности на малочисленных классах, можно использовать Upsampling, Downsampling или SMOTE. Но нужно учесть, что если данные будут сильно разниться, то эффект от преобразования может быть неоднозначным (может ухудшить качество при одних и тех же настройках на разных данных).
* Также была проверена лемматизация, но данные не совсем подходящие. Удалось получить незначительное повышение точности в некоторых тестах с этим подходом.

---
### **Выбор итогового решения:**
По итогу была выбрана модель **TF-IDF + OHE**, так как этот метод показывает высокую точность по метрикам и его проще адаптировать и обучить на новые данные.
Но в зависимости от частоты изменений данных, можно использовать и CatBoost, если данные не будут меняться слишком часто.



